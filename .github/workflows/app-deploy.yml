name: App Deployment

on:
  repository_dispatch:
    types: [trigger-deployment]
  workflow_dispatch:

concurrency:
  group: app-deploy-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Guard job to check branch and username
  pre-check:
    runs-on: self-hosted
    outputs:
      can_deploy: ${{ steps.set-output.outputs.can_deploy }}
    steps:
      - name: Check if deployment should run
        id: set-output
        run: |
          echo "ref=${{ github.ref }}"
          echo "event_name=${{ github.event_name }}"
          echo "actor=${{ github.actor }}"

          CAN_DEPLOY=false

          # Condition 1: Deployments from main branch
          if [ "${{ github.ref }}" = "refs/heads/main" ]; then
            echo "✅ Allowed: main branch"
            CAN_DEPLOY=true
          fi

          # Condition 2: Manual trigger + correct actor
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ "${{ github.actor }}" = "Mahesh-Kotakonda" ]; then
            echo "✅ Allowed: manual trigger by Mahesh-Kotakonda"
            CAN_DEPLOY=true
          fi

          if [ "$CAN_DEPLOY" = true ]; then
            echo "can_deploy=true" >> $GITHUB_OUTPUT
          else
            echo "⚠️ Not allowed to deploy (must be main branch OR manual trigger by Mahesh-Kotakonda)"
            echo "can_deploy=false" >> $GITHUB_OUTPUT
          fi

  deploy:
    needs: pre-check
    if: needs.pre-check.outputs.can_deploy == 'true'
    runs-on: self-hosted
    environment:
      name: production

    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: us-east-1
      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
      IMAGE_REPO: multi-cloud-cost-and-service-status-dashboard-repo
      SSM_PARAM_NAME: myapp_database_credentials
      S3_JSON_PATH: s3://multi-cloud-cost-and-service-status-dashboard/infra/multi-cloud-dashboard-outputs.json

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ env.DOCKERHUB_USERNAME }}
          password: ${{ env.DOCKERHUB_TOKEN }}

      - name: Fetch DB credentials from SSM
        run: |
          PARAM_VALUE=$(aws ssm get-parameter --name "$SSM_PARAM_NAME" --with-decryption --query "Parameter.Value" --output text)
          DB_USER=$(echo $PARAM_VALUE | jq -r '.username')
          DB_PASS=$(echo $PARAM_VALUE | jq -r '.password')
          echo "DB_USER=$DB_USER" >> $GITHUB_ENV
          echo "DB_PASS=$DB_PASS" >> $GITHUB_ENV

      # - name: Deploy Worker
      #   run: |
      #     PEM_PATH=~/ssh-keys/multi-cloud-cost-and-service-status-key.pem
      #     aws s3 cp "$S3_JSON_PATH" worker-outputs.json
      #     DB_HOST=$(jq -r '.db.endpoint | split(":")[0]' worker-outputs.json)
      #     DB_NAME=$(jq -r '.db.name' worker-outputs.json)
      #     INSTANCE_IDS=$(jq -r '.ec2_instance_ids[]' worker-outputs.json)
      
      #     for ID in $INSTANCE_IDS; do
      #       IP=$(aws ec2 describe-instances --instance-ids $ID --query "Reservations[0].Instances[0].PublicIpAddress" --output text)
      
      #       # Remove previous failed container
      #       ssh -o StrictHostKeyChecking=no -i "$PEM_PATH" ec2-user@"$IP" \
      #         "sudo docker rm -f worker_new >/dev/null 2>&1 || true"
      
      #       # Deploy new container with explicit AWS and DB credentials
      #       ssh -o StrictHostKeyChecking=no -i "$PEM_PATH" ec2-user@"$IP" \
      #         "docker login -u '$DOCKERHUB_USERNAME' --password-stdin <<< '$DOCKERHUB_TOKEN'; \
      #          docker pull $DOCKERHUB_USERNAME/$IMAGE_REPO:worker-latest; \
      #          docker run -d --name worker_new \
      #            -e AWS_ACCESS_KEY_ID='$AWS_ACCESS_KEY_ID' \
      #            -e AWS_SECRET_ACCESS_KEY='$AWS_SECRET_ACCESS_KEY' \
      #            -e AWS_REGION='$AWS_REGION' \
      #            -e DB_HOST='$DB_HOST' \
      #            -e DB_NAME='$DB_NAME' \
      #            -e DB_USER='$DB_USER' \
      #            -e DB_PASS='$DB_PASS' \
      #            -e POLL_INTERVAL_SECONDS=60000 \
      #            $DOCKERHUB_USERNAME/$IMAGE_REPO:worker-latest"
      
      #       echo "⏳ Waiting for worker_new to stabilize on $IP ..."
      #       sleep 30
      
      #       STATUS=$(ssh -o StrictHostKeyChecking=no -i "$PEM_PATH" ec2-user@"$IP" \
      #         "sudo docker ps --filter 'name=worker_new' --filter 'status=running' | grep worker_new >/dev/null 2>&1; echo \$?")
      
      #       if [ "$STATUS" -eq 0 ]; then
      #         echo "✅ New worker is healthy on $IP. Replacing old worker..."
      #         ssh -o StrictHostKeyChecking=no -i "$PEM_PATH" ec2-user@"$IP" \
      #           "sudo docker rm -f worker || true; sudo docker rename worker_new worker"
      #       else
      #         echo "❌ New worker failed on $IP. Printing logs..."
      #         ssh -o StrictHostKeyChecking=no -i "$PEM_PATH" ec2-user@"$IP" \
      #           "echo '--- Worker Logs (last 200 lines) ---'; \
      #            sudo docker logs --tail=200 worker_new || true; \
      #            echo '--- Worker Inspect Info ---'; \
      #            sudo docker inspect worker_new --format='Status: {{.State.Status}}, ExitCode: {{.State.ExitCode}}, Error: {{.State.Error}}' || true; \
      #            sudo docker rm -f worker_new || true"
      #         echo "⚠️ Rollout stopped. Old worker kept on $IP."
      #         exit 1
      #       fi
      #     done




      #########################################
      # Deploy Backend (Blue-Green Deployment)
      #########################################
      - name: Deploy Backend (Blue-Green)
        run: |
          set -euo pipefail
      
          # Path to SSH key
          PEM_PATH=~/ssh-keys/multi-cloud-cost-and-service-status-key.pem
      
          # Download Terraform backend outputs
          aws s3 cp "$S3_JSON_PATH" backend-outputs.json
      
          # Extract DB details
          DB_ENDPOINT=$(jq -r '.db.endpoint' backend-outputs.json)
          DB_HOST=$(echo "$DB_ENDPOINT" | cut -d: -f1)
          DB_PORT=$(echo "$DB_ENDPOINT" | cut -d: -f2)
          DB_NAME=$(jq -r '.db.name' backend-outputs.json)
      
          # Extract infra details
          INSTANCE_IDS=$(jq -r '.ec2_instance_ids | join(",")' backend-outputs.json)
          BACKEND_BLUE_TG=$(jq -r '.backend_blue_tg_arn' backend-outputs.json)
          BACKEND_GREEN_TG=$(jq -r '.backend_green_tg_arn' backend-outputs.json)
      
          # Call the backend deploy script with all params including AWS creds
          ./deploy/deploy-backend.sh \
            --outputs-json backend-outputs.json \
            --pem-path "$PEM_PATH" \
            --db-host "$DB_HOST" \
            --db-port "$DB_PORT" \
            --db-name "$DB_NAME" \
            --db-user "${DB_USER}" \
            --db-pass "${DB_PASS}" \
            --dockerhub-username "${DOCKERHUB_USERNAME}" \
            --dockerhub-token "${DOCKERHUB_TOKEN}" \
            --image-repo "${IMAGE_REPO}" \
            --instance-ids "$INSTANCE_IDS" \
            --blue-tg "$BACKEND_BLUE_TG" \
            --green-tg "$BACKEND_GREEN_TG" \
            --aws-access-key-id "${AWS_ACCESS_KEY_ID}" \
            --aws-secret-access-key "${AWS_SECRET_ACCESS_KEY}" \
            --aws-region "${AWS_REGION}"


      #########################################
      # Deploy Frontend (Blue-Green Deployment)
      #########################################
      - name: Deploy Frontend (Blue-Green)
        run: |
          set -euo pipefail
      
          # Path to SSH key
          PEM_PATH=~/ssh-keys/multi-cloud-cost-and-service-status-key.pem
      
          # Download Terraform frontend outputs
          aws s3 cp "$S3_JSON_PATH" frontend-outputs.json
      
          # Extract frontend details
          INSTANCE_IDS=$(jq -r '.ec2_instance_ids | join(",")' frontend-outputs.json)
          FRONTEND_BLUE_TG=$(jq -r '.frontend_blue_tg_arn' frontend-outputs.json)
          FRONTEND_GREEN_TG=$(jq -r '.frontend_green_tg_arn' frontend-outputs.json)
      
          # Call the frontend deploy script with all params including AWS creds
          ./deploy/deploy-frontend.sh \
            --outputs-json frontend-outputs.json \
            --pem-path "$PEM_PATH" \
            --dockerhub-username "${DOCKERHUB_USERNAME}" \
            --dockerhub-token "${DOCKERHUB_TOKEN}" \
            --image-repo "${IMAGE_REPO}" \
            --instance-ids "$INSTANCE_IDS" \
            --blue-tg "$FRONTEND_BLUE_TG" \
            --green-tg "$FRONTEND_GREEN_TG" \
            --aws-access-key-id "${AWS_ACCESS_KEY_ID}" \
            --aws-secret-access-key "${AWS_SECRET_ACCESS_KEY}" \
            --aws-region "${AWS_REGION}"

      






